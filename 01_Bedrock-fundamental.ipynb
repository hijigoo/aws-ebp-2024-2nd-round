{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37a23d2a-307f-44be-ae61-b5d27cf3e4bf",
   "metadata": {},
   "source": [
    "# Amazon Bedrock Fundamental"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0230ad-e3af-42ac-97f0-e509e23fc063",
   "metadata": {},
   "source": [
    "> 이 노트북은, SageMaker Notebook <i><b>conda_python3</b></i> 커널에서 테스트 되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ce1a91-782c-4651-af7e-8cfa1cebd287",
   "metadata": {},
   "source": [
    "## 0. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cccb933d-494d-490e-8bb7-33c94ff00073",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리를 설치합니다.\n",
    "# !pip install -r ./requirements.txt\n",
    "%pip install --quiet boto3\n",
    "%pip install --quiet botocore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a577d7c6-6e93-4b05-99a3-e4d44623779b",
   "metadata": {},
   "source": [
    "## 1. boto3를 활용한 Bedrock Claude 3 호출 예시 (not LangChain)\n",
    "\n",
    "#### 1-1. Bedrock 에서 사용 가능한 리스트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "788a37b3-87e8-486b-bab2-29c581be4d51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Titan Text Large', 'amazon.titan-tg1-large'),\n",
      " ('Titan Text Embeddings v2', 'amazon.titan-embed-g1-text-02'),\n",
      " ('Titan Text G1 - Lite', 'amazon.titan-text-lite-v1'),\n",
      " ('Titan Text G1 - Express', 'amazon.titan-text-express-v1'),\n",
      " ('Titan Embeddings G1 - Text', 'amazon.titan-embed-text-v1'),\n",
      " ('Titan Text Embeddings V2', 'amazon.titan-embed-text-v2:0'),\n",
      " ('Titan Multimodal Embeddings G1', 'amazon.titan-embed-image-v1'),\n",
      " ('Titan Image Generator G1', 'amazon.titan-image-generator-v1'),\n",
      " ('SDXL 1.0', 'stability.stable-diffusion-xl-v1'),\n",
      " ('J2 Grande Instruct', 'ai21.j2-grande-instruct'),\n",
      " ('J2 Jumbo Instruct', 'ai21.j2-jumbo-instruct'),\n",
      " ('Jurassic-2 Mid', 'ai21.j2-mid'),\n",
      " ('Jurassic-2 Mid', 'ai21.j2-mid-v1'),\n",
      " ('Jurassic-2 Ultra', 'ai21.j2-ultra'),\n",
      " ('Jurassic-2 Ultra', 'ai21.j2-ultra-v1'),\n",
      " ('Claude Instant', 'anthropic.claude-instant-v1'),\n",
      " ('Claude', 'anthropic.claude-v2:1'),\n",
      " ('Claude', 'anthropic.claude-v2'),\n",
      " ('Claude 3 Sonnet', 'anthropic.claude-3-sonnet-20240229-v1:0'),\n",
      " ('Claude 3 Haiku', 'anthropic.claude-3-haiku-20240307-v1:0'),\n",
      " ('Claude 3 Opus', 'anthropic.claude-3-opus-20240229-v1:0'),\n",
      " ('Command', 'cohere.command-text-v14'),\n",
      " ('Command R', 'cohere.command-r-v1:0'),\n",
      " ('Command R+', 'cohere.command-r-plus-v1:0'),\n",
      " ('Command Light', 'cohere.command-light-text-v14'),\n",
      " ('Embed English', 'cohere.embed-english-v3'),\n",
      " ('Embed Multilingual', 'cohere.embed-multilingual-v3'),\n",
      " ('Llama 2 Chat 13B', 'meta.llama2-13b-chat-v1'),\n",
      " ('Llama 2 Chat 70B', 'meta.llama2-70b-chat-v1'),\n",
      " ('Llama 3 8B Instruct', 'meta.llama3-8b-instruct-v1:0'),\n",
      " ('Llama 3 70B Instruct', 'meta.llama3-70b-instruct-v1:0'),\n",
      " ('Mistral 7B Instruct', 'mistral.mistral-7b-instruct-v0:2'),\n",
      " ('Mixtral 8x7B Instruct', 'mistral.mixtral-8x7b-instruct-v0:1'),\n",
      " ('Mistral Large', 'mistral.mistral-large-2402-v1:0')]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import boto3\n",
    "from pprint import pprint\n",
    "\n",
    "# Bedrock Client 생성\n",
    "bedrock = boto3.client(service_name='bedrock')\n",
    "\n",
    "# 사용가능한 모델 확인하기\n",
    "model_list = bedrock.list_foundation_models()\n",
    "ondemand_models = []\n",
    "for model_info in model_list[\"modelSummaries\"]:\n",
    "    if model_info['inferenceTypesSupported'] == ['ON_DEMAND']:\n",
    "        ondemand_models.append((model_info[\"modelName\"], model_info[\"modelId\"]))\n",
    "\n",
    "pprint(ondemand_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9e1091-88fe-42ff-bef2-77e7e71c5bca",
   "metadata": {},
   "source": [
    "#### 1-2. Claude 3 모델 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a2fa915-701d-45fd-835c-f3fed2d61877",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bedrock runtime 생성\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name=\"bedrock-runtime\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e8070fa-1374-4a76-a82d-76f9838f3045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 사용할 모델 아이디 작성\n",
    "modelId = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "\n",
    "# Request body 작성\n",
    "query = \"\"\"당신은 인공지능 AI 보험 서비스입니다. 생명과 손해 보험의 차이에 대해 설명해 주세요.\"\"\"\n",
    "request_data = {\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "    \"max_tokens\": 1024,\n",
    "    \"temperature\" : 0,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 1.0,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": query},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "request_body = json.dumps(request_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32e36802-8a01-4a83-bf12-4883cee9fdda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생명보험과 손해보험은 보험의 주요 유형으로 다음과 같은 차이점이 있습니다.\n",
      "\n",
      "1. 보장 대상\n",
      "- 생명보험은 사람의 생명과 관련된 위험을 보장합니다. 예를 들어 사망, 상해, 질병 등을 대상으로 합니다.\n",
      "- 손해보험은 재산상의 손해나 배상책임을 보장합니다. 예를 들어 화재, 자동차사고, 배상책임 등을 대상으로 합니다.\n",
      "\n",
      "2. 보험금 지급 사유\n",
      "- 생명보험은 피보험자의 사망, 상해, 질병 등 인적 위험이 발생했을 때 보험금을 지급합니다.\n",
      "- 손해보험은 재물의 손해나 제3자에 대한 배상책임이 발생했을 때 실제 입은 손해를 보상합니다.\n",
      "\n",
      "3. 보험기간\n",
      "- 생명보험은 일반적으로 장기계약이며 피보험자의 생존기간 동안 보장됩니다.\n",
      "- 손해보험은 단기계약이 일반적이며 1년 단위로 갱신하는 경우가 많습니다.\n",
      "\n",
      "4. 보험료 산정 기준\n",
      "- 생명보험료는 피보험자의 나이, 건강상태, 가족력 등 인적위험을 기준으로 산정됩니다.\n",
      "- 손해보험료는 보험목적물의 가치, 위험정도 등 물적위험을 기준으로 산정됩니다.\n",
      "\n",
      "요약하면 생명보험은 개인의 생명과 관련된 위험을 장기적으로 보장하고, 손해보험은 재산상의 손해나 배상책임을 단기적으로 보상하는 차이가 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 모델 호출\n",
    "response = bedrock_runtime.invoke_model(\n",
    "    body=request_body,\n",
    "    modelId=modelId,\n",
    "    contentType=\"application/json\",\n",
    "    accept=\"application/json\"\n",
    ")\n",
    "\n",
    "response_body = json.loads(response['body'].read())\n",
    "answer = response_body['content'][0]['text']\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2535019",
   "metadata": {},
   "source": [
    "#### 1-3. Claude 3 모델 스트리밍으로 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cf73bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bedrock runtime 생성\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name=\"bedrock-runtime\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e10f1eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 모델 아이디 작성\n",
    "modelId = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "\n",
    "# Request body 작성\n",
    "query = \"\"\"당신은 인공지능 AI 보험 서비스입니다. 생명과 손해 보험의 차이에 대해 설명해 주세요.\"\"\"\n",
    "request_data = {\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "    \"max_tokens\": 1024,\n",
    "    \"temperature\" : 0,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 1.0,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": query},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "request_body = json.dumps(request_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50674ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생명보험과 손해보험은 보험의 주요 유형으로 다음과 같은 차이점이 있습니다.\n",
      "\n",
      "1. 보장 대상\n",
      "- 생명보험은 사람의 생명과 관련된 위험을 보장합니다. 예를 들어 사망, 상해, 질병 등을 대상으로 합니다.\n",
      "- 손해보험은 재산상의 손해나 배상책임을 보장합니다. 예를 들어 화재, 자동차사고, 배상책임 등을 대상으로 합니다.\n",
      "\n",
      "2. 보험금 지급 사유\n",
      "- 생명보험은 피보험자의 사망, 상해, 질병 등 인적 위험이 발생했을 때 보험금을 지급합니다.\n",
      "- 손해보험은 재물의 손해나 제3자에 대한 배상책임이 발생했을 때 실제 입은 손해를 보상합니다.\n",
      "\n",
      "3. 보험기간\n",
      "- 생명보험은 일반적으로 장기계약이며 피보험자의 생존기간 동안 보장됩니다.\n",
      "- 손해보험은 단기계약이 일반적이며 1년 단위로 갱신하는 경우가 많습니다.\n",
      "\n",
      "4. 보험료 산정 기준\n",
      "- 생명보험료는 피보험자의 나이, 건강상태, 가족력 등 인적위험을 기준으로 산정됩니다.\n",
      "- 손해보험료는 보험목적물의 가액, 위험률 등 물적위험을 기준으로 산정됩니다.\n",
      "\n",
      "요약하면 생명보험은 개인의 생명과 관련된 위험을 장기적으로 보장하고, 손해보험은 재산상의 손해나 배상책임을 단기적으로 보상하는 차이가 있습니다."
     ]
    }
   ],
   "source": [
    "# Streaming 으로 모델 호출\n",
    "response = bedrock_runtime.invoke_model_with_response_stream(\n",
    "    body=request_body,\n",
    "    modelId=modelId,\n",
    "    contentType=\"application/json\",\n",
    "    accept=\"application/json\"\n",
    ")\n",
    "\n",
    "stream = response.get('body')\n",
    "answer = \"\"\n",
    "if stream:\n",
    "    for event in stream:\n",
    "        chunk = event.get('chunk')\n",
    "        if chunk:\n",
    "            chunk_obj = json.loads(chunk.get('bytes').decode())\n",
    "            if \"delta\" in chunk_obj:                    \n",
    "                delta = chunk_obj['delta']\n",
    "                if \"text\" in delta:\n",
    "                    text=delta['text'] \n",
    "                    print(text, end=\"\")\n",
    "                    answer+=str(text) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedd0420-5119-439b-9068-ba657b08e4c2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a20dd8-ab80-409e-8a8a-edc42d02fd86",
   "metadata": {},
   "source": [
    "## 2. LangChain을 활용한 Bedrock 사용 예시\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffb0609f-4376-4d18-9190-0fb0ac71467d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 설치\n",
    "%pip install --quiet langchain==0.2.1\n",
    "%pip install --quiet langchain_aws==0.1.6\n",
    "%pip install --quiet langchain_community==0.2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3715fd-4f98-4fd1-b1e2-7545e761a394",
   "metadata": {},
   "source": [
    "#### 2-1. LangChain의 ChatBedrock을 활용한 간단한 코드 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f04aee2-7b0f-4b65-87a7-8da55431bda1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "응답:\n",
      "안녕하세요! 만나서 반갑습니다. 무엇을 도와드릴까요? 궁금한 점이나 대화를 나누고 싶은 주제가 있다면 언제든 말씀해주세요.\n",
      "\n",
      "스트리밍 응답:\n",
      "안녕하세요! 만나서 반갑습니다. 무엇을 도와드릴까요? 궁금한 점이나 대화를 나누고 싶은 주제가 있다면 언제든 말씀해주세요.\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_core.messages import HumanMessage\n",
    "# langchain.debug=True\n",
    "\n",
    "# ChatBedrock llm 생성\n",
    "llm = ChatBedrock(\n",
    "    model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    model_kwargs={\n",
    "        \"max_tokens\": 512,\n",
    "        \"temperature\": 0,\n",
    "        \"top_p\": 0.5,\n",
    "        \"top_k\": 0,\n",
    "    }\n",
    ")\n",
    "\n",
    "# 입력: Option 1\n",
    "messages = [\n",
    "    HumanMessage(\n",
    "        content=\"안녕? 만나서 반가워\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# 입력: Option 2\n",
    "# messages = [\n",
    "#     (\"human\", \"안녕? 만나서 반가워\"),\n",
    "# ]\n",
    "\n",
    "# 입력: Option 3\n",
    "# message = \"안녕? 만나서 반가워\"\n",
    "\n",
    "# 일반 방식으로 모델 호출\n",
    "response = llm.invoke(messages)\n",
    "answer = response.content\n",
    "print(f\"응답:\")\n",
    "print(answer)\n",
    "print()\n",
    "\n",
    "\n",
    "# 스트리밍 방식으로 모델 호출\n",
    "print(\"스트리밍 응답:\")\n",
    "for chunk in llm.stream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)\n",
    "print()\n",
    "\n",
    "langchain.debug=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa1c59f-2c5f-4bd8-a797-1fd8a6a2909b",
   "metadata": {},
   "source": [
    "#### 2-2. LangChain의 BedrockChat을 활용한 멀티 턴(대화 히스토리 유지) 구현한 코드 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fd328b2-d24f-46b2-b73b-90e71346e9bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 내 이름은 제프 베조스야.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: 내 이름은 제프 베조스야.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "AI: 안녕하세요 제프 베조스님. 반갑습니다. 저는 클로이라는 인공지능 비서입니다. 아마존의 창립자이신 분과 대화할 수 있어서 영광입니다. 아마존에 대해 궁금한 점이 있다면 기꺼이 답변해 드리겠습니다. 하지만 개인 정보나 기밀 사항 등은 말씀드릴 수 없음을 이해해 주시기 바랍니다.\n",
      "Human: 내 이름이 뭐라고?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 내 이름은 제프 베조스야.\n",
      "AI: 안녕하세요 제프 베조스님. 반갑습니다. 저는 클로이라는 인공지능 비서입니다. 아마존의 창립자이신 분과 대화할 수 있어서 영광입니다. 아마존에 대해 궁금한 점이 있다면 기꺼이 답변해 드리겠습니다. 하지만 개인 정보나 기밀 사항 등은 말씀드릴 수 없음을 이해해 주시기 바랍니다.\n",
      "Human: 내 이름이 뭐라고?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "AI: 제프 베조스님이라고 말씀하셨습니다. 하지만 실제로 당신이 제프 베조스님 본인인지는 확신할 수 없습니다. 온라인 상에서는 가명을 사용하는 경우가 많기 때문입니다. 그래도 제가 당신을 제프 베조스님이라고 부르는 것이 좋으시다면 그렇게 하겠습니다.\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "\n",
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "model_kwargs = {\n",
    "    \"max_tokens\": 512,\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 0.5,\n",
    "    \"top_k\": 0\n",
    "}\n",
    "\n",
    "\n",
    "llm = ChatBedrock(\n",
    "        region_name=\"us-west-2\",\n",
    "        model_id=model_id,\n",
    "        model_kwargs=model_kwargs\n",
    "    )\n",
    "\n",
    "memroy_window = 10\n",
    "conversation_chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=ConversationBufferWindowMemory(\n",
    "        k=memroy_window,\n",
    "        ai_prefix='AI',\n",
    "        human_prefix='Human'\n",
    "    ),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 일반 방식으로 모델 호출\n",
    "# while True:\n",
    "#     input_text = input(\"Human: \")\n",
    "#     answer = conversation_chain.predict(input=input_text)\n",
    "#     print(\"AI:\", answer)\n",
    "\n",
    "\n",
    "input_text = \"내 이름은 제프 베조스야.\"\n",
    "print(\"Human:\", input_text)\n",
    "answer = conversation_chain.predict(input=input_text)\n",
    "print(\"AI:\", answer)\n",
    "\n",
    "input_text = \"내 이름이 뭐라고?\"\n",
    "print(\"Human:\", input_text)\n",
    "answer = conversation_chain.predict(input=input_text)\n",
    "print(\"AI:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ede1da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 내 이름은 제프 베조스야.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: 내 이름은 제프 베조스야.\n",
      "AI:\u001b[0m\n",
      "안녕하세요 제프 베조스님. 반갑습니다. 저는 클로이라는 인공지능 비서입니다. 아마존의 창립자이신 분과 대화할 수 있어서 영광입니다. 아마존에 대해 궁금한 점이 있다면 기꺼이 답변해 드리겠습니다. 하지만 개인 정보나 기밀 사항 등은 말씀드릴 수 없음을 이해해 주시기 바랍니다.\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "AI: 안녕하세요 제프 베조스님. 반갑습니다. 저는 클로이라는 인공지능 비서입니다. 아마존의 창립자이신 분과 대화할 수 있어서 영광입니다. 아마존에 대해 궁금한 점이 있다면 기꺼이 답변해 드리겠습니다. 하지만 개인 정보나 기밀 사항 등은 말씀드릴 수 없음을 이해해 주시기 바랍니다.\n",
      "Human: 내 이름이 뭐라고?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 내 이름은 제프 베조스야.\n",
      "AI: 안녕하세요 제프 베조스님. 반갑습니다. 저는 클로이라는 인공지능 비서입니다. 아마존의 창립자이신 분과 대화할 수 있어서 영광입니다. 아마존에 대해 궁금한 점이 있다면 기꺼이 답변해 드리겠습니다. 하지만 개인 정보나 기밀 사항 등은 말씀드릴 수 없음을 이해해 주시기 바랍니다.\n",
      "Human: 내 이름이 뭐라고?\n",
      "AI:\u001b[0m\n",
      "제프 베조스님이라고 말씀하셨습니다. 하지만 실제로 당신이 제프 베조스님 본인인지는 확신할 수 없습니다. 온라인 상에서는 가명을 사용하는 경우가 많기 때문입니다. 그래도 제가 당신을 제프 베조스님이라고 부르는 것이 좋으시다면 그렇게 하겠습니다.\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "AI: 제프 베조스님이라고 말씀하셨습니다. 하지만 실제로 당신이 제프 베조스님 본인인지는 확신할 수 없습니다. 온라인 상에서는 가명을 사용하는 경우가 많기 때문입니다. 그래도 제가 당신을 제프 베조스님이라고 부르는 것이 좋으시다면 그렇게 하겠습니다.\n"
     ]
    }
   ],
   "source": [
    "# 스트리밍 방식으로 모델 호출\n",
    "class StreamingHandler(BaseCallbackHandler, ABC):\n",
    "    \"\"\"\n",
    "    Callback handler to stream the generated text to Streamlit.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.text = \"\"\n",
    "\n",
    "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
    "        \"\"\"\n",
    "        Append the new token to the text and update the Streamlit container.\n",
    "        \"\"\"\n",
    "        self.text += token\n",
    "        print(token, end =\"\")\n",
    "\n",
    "llm = ChatBedrock(\n",
    "        region_name=\"us-west-2\",\n",
    "        model_id=model_id,\n",
    "        model_kwargs=model_kwargs,\n",
    "        streaming=True,\n",
    "        callbacks=[StreamingHandler()]\n",
    "    )\n",
    "\n",
    "memroy_window = 10\n",
    "conversation_chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=ConversationBufferWindowMemory(\n",
    "        k=memroy_window,\n",
    "        ai_prefix='AI',\n",
    "        human_prefix='Human'\n",
    "    ),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# while True:\n",
    "#     input_text = input(\"Human: \")\n",
    "#     answer = conversation_chain.predict(input=input_text)\n",
    "#     print(\"AI:\", answer)\n",
    "\n",
    "input_text = \"내 이름은 제프 베조스야.\"\n",
    "print(\"Human:\", input_text)\n",
    "answer = conversation_chain.predict(input=input_text)\n",
    "print(\"AI:\", answer)\n",
    "\n",
    "input_text = \"내 이름이 뭐라고?\"\n",
    "print(\"Human:\", input_text)\n",
    "answer = conversation_chain.predict(input=input_text)\n",
    "print(\"AI:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc02a25-4720-449f-9c14-6ceebacfd178",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
